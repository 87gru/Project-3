{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for query\n",
    "begin_date = '2013-01-01T00:00:00.000'\n",
    "end_date = '2014-01-01T00:00:00.000'\n",
    "borough = 'MANHATTAN' #Choose one of the five boroughs\n",
    "\n",
    "# This query URL will get all rows based on date range\n",
    "base_query = f\"https://data.cityofnewyork.us/resource/qgea-i56i.json?$where=rpt_dt%20between%20%27{begin_date}%27%20and%20%27{end_date}%27\"\n",
    "\n",
    "# This query will search the same date range but also filter by borough\n",
    "borough_query = f\"https://data.cityofnewyork.us/resource/qgea-i56i.json?$where=boro_nm%20=%20%27{borough}%27%20and%20rpt_dt%20between%20%27{begin_date}%27%20and%20%27{end_date}%27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store fields from the JSON\n",
    "complaint_number = [] #'cmplnt_num'\n",
    "reported_date = [] #'rpt_dt'\n",
    "borough_name = [] #'boro_nm'\n",
    "offense_desc = [] #'ofns_desc'\n",
    "pd_desc = [] # 'pd_desc'\n",
    "law_cat = [] #law_cat_cd\n",
    "lat = [] #latitude\n",
    "lon = [] #longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for the For Loop.\n",
    "records_count = 1\n",
    "records = 0\n",
    "offset = 0\n",
    "set = 1\n",
    "limit = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 1000 rows of data, Set # 1\n",
      "Extracting 1000 rows of data, Set # 2\n",
      "Extracting 1000 rows of data, Set # 3\n",
      "Extracting 1000 rows of data, Set # 4\n",
      "Extracting 1000 rows of data, Set # 5\n",
      "Extracting 1000 rows of data, Set # 6\n",
      "Extracting 1000 rows of data, Set # 7\n",
      "Extracting 1000 rows of data, Set # 8\n",
      "Extracting 1000 rows of data, Set # 9\n",
      "Extracting 1000 rows of data, Set # 10\n",
      "Extracting 1000 rows of data, Set # 11\n",
      "Extracting 1000 rows of data, Set # 12\n",
      "Extracting 1000 rows of data, Set # 13\n",
      "Extracting 1000 rows of data, Set # 14\n",
      "Extracting 1000 rows of data, Set # 15\n",
      "Extracting 1000 rows of data, Set # 16\n",
      "Extracting 1000 rows of data, Set # 17\n",
      "Extracting 1000 rows of data, Set # 18\n",
      "Extracting 1000 rows of data, Set # 19\n",
      "Extracting 1000 rows of data, Set # 20\n",
      "Extracting 1000 rows of data, Set # 21\n",
      "Extracting 1000 rows of data, Set # 22\n",
      "Extracting 1000 rows of data, Set # 23\n",
      "Extracting 1000 rows of data, Set # 24\n",
      "Extracting 1000 rows of data, Set # 25\n",
      "Extracting 1000 rows of data, Set # 26\n",
      "Extracting 1000 rows of data, Set # 27\n",
      "Extracting 1000 rows of data, Set # 28\n",
      "Extracting 1000 rows of data, Set # 29\n",
      "Extracting 1000 rows of data, Set # 30\n",
      "Extracting 1000 rows of data, Set # 31\n",
      "Extracting 1000 rows of data, Set # 32\n",
      "Extracting 1000 rows of data, Set # 33\n",
      "Extracting 1000 rows of data, Set # 34\n",
      "Extracting 1000 rows of data, Set # 35\n",
      "Extracting 1000 rows of data, Set # 36\n",
      "Extracting 1000 rows of data, Set # 37\n",
      "Extracting 1000 rows of data, Set # 38\n",
      "Extracting 1000 rows of data, Set # 39\n",
      "Extracting 1000 rows of data, Set # 40\n",
      "Extracting 1000 rows of data, Set # 41\n",
      "Extracting 1000 rows of data, Set # 42\n",
      "Extracting 1000 rows of data, Set # 43\n",
      "Extracting 1000 rows of data, Set # 44\n",
      "Extracting 1000 rows of data, Set # 45\n",
      "Extracting 1000 rows of data, Set # 46\n",
      "Extracting 1000 rows of data, Set # 47\n",
      "Extracting 1000 rows of data, Set # 48\n",
      "Extracting 1000 rows of data, Set # 49\n",
      "Extracting 1000 rows of data, Set # 50\n",
      "Extracting 1000 rows of data, Set # 51\n",
      "Extracting 1000 rows of data, Set # 52\n",
      "Extracting 1000 rows of data, Set # 53\n",
      "Extracting 1000 rows of data, Set # 54\n",
      "Extracting 1000 rows of data, Set # 55\n",
      "Extracting 1000 rows of data, Set # 56\n",
      "Extracting 1000 rows of data, Set # 57\n",
      "Extracting 1000 rows of data, Set # 58\n",
      "Extracting 1000 rows of data, Set # 59\n",
      "Extracting 1000 rows of data, Set # 60\n",
      "Extracting 1000 rows of data, Set # 61\n",
      "Extracting 1000 rows of data, Set # 62\n",
      "Extracting 1000 rows of data, Set # 63\n",
      "Extracting 1000 rows of data, Set # 64\n",
      "Extracting 1000 rows of data, Set # 65\n",
      "Extracting 1000 rows of data, Set # 66\n",
      "Extracting 1000 rows of data, Set # 67\n",
      "Extracting 1000 rows of data, Set # 68\n",
      "Extracting 1000 rows of data, Set # 69\n",
      "Extracting 1000 rows of data, Set # 70\n",
      "Extracting 1000 rows of data, Set # 71\n",
      "Extracting 1000 rows of data, Set # 72\n",
      "Extracting 1000 rows of data, Set # 73\n",
      "Extracting 1000 rows of data, Set # 74\n",
      "Extracting 1000 rows of data, Set # 75\n",
      "Extracting 1000 rows of data, Set # 76\n",
      "Extracting 1000 rows of data, Set # 77\n",
      "Extracting 1000 rows of data, Set # 78\n",
      "Extracting 1000 rows of data, Set # 79\n",
      "Extracting 1000 rows of data, Set # 80\n",
      "Extracting 1000 rows of data, Set # 81\n",
      "Extracting 1000 rows of data, Set # 82\n",
      "Extracting 1000 rows of data, Set # 83\n",
      "Extracting 1000 rows of data, Set # 84\n",
      "Extracting 1000 rows of data, Set # 85\n",
      "Extracting 1000 rows of data, Set # 86\n",
      "Extracting 1000 rows of data, Set # 87\n",
      "Extracting 1000 rows of data, Set # 88\n",
      "Extracting 1000 rows of data, Set # 89\n",
      "Extracting 1000 rows of data, Set # 90\n",
      "Extracting 1000 rows of data, Set # 91\n",
      "Extracting 1000 rows of data, Set # 92\n",
      "Extracting 1000 rows of data, Set # 93\n",
      "Extracting 1000 rows of data, Set # 94\n",
      "Extracting 1000 rows of data, Set # 95\n",
      "Extracting 1000 rows of data, Set # 96\n",
      "Extracting 1000 rows of data, Set # 97\n",
      "Extracting 1000 rows of data, Set # 98\n",
      "Extracting 1000 rows of data, Set # 99\n",
      "Extracting 1000 rows of data, Set # 100\n",
      "Extracting 1000 rows of data, Set # 101\n",
      "Extracting 1000 rows of data, Set # 102\n",
      "Extracting 1000 rows of data, Set # 103\n",
      "Extracting 1000 rows of data, Set # 104\n",
      "Extracting 1000 rows of data, Set # 105\n",
      "Extracting 1000 rows of data, Set # 106\n",
      "Extracting 1000 rows of data, Set # 107\n",
      "Extracting 1000 rows of data, Set # 108\n",
      "Extracting 1000 rows of data, Set # 109\n",
      "Extracting 1000 rows of data, Set # 110\n",
      "Extracting 1000 rows of data, Set # 111\n",
      "Extracting 1000 rows of data, Set # 112\n",
      "Extracting 1000 rows of data, Set # 113\n",
      "Extracting 1000 rows of data, Set # 114\n",
      "Extracting 1000 rows of data, Set # 115\n",
      "Extracting 1000 rows of data, Set # 116\n",
      "Extracting 1000 rows of data, Set # 117\n",
      "Extracting 1000 rows of data, Set # 118\n",
      "Extracting 688 rows of data, Set # 119\n",
      "Extracting 0 rows of data, Set # 120\n",
      "Total number of records extracted: 118688\n"
     ]
    }
   ],
   "source": [
    "# While loop. While len of json_results > 0, query the URL.\n",
    "while records_count != 0:\n",
    "    # Define the limit/offset portion of the URL. Updates after every iteration. The limit is default set to 1000, per API documentation.\n",
    "    limit_query = f\"&$limit=1000&$offset={offset}\"\n",
    "    # Get the JSON\n",
    "    json_results = requests.get(borough_query,limit_query).json()\n",
    "    # Add to the number of results to track total number\n",
    "    records += len(json_results)\n",
    "    # Print message to console showing number of rows extracted, show set number.\n",
    "    print(f\"Extracting {len(json_results)} rows of data, Set # {set}\")\n",
    "    # Extract and store requested data into lists\n",
    "    for x in range(len(json_results)):\n",
    "        complaint_number.append(json_results[x]['cmplnt_num'])\n",
    "        reported_date.append(json_results[x]['rpt_dt'])\n",
    "        borough_name.append(json_results[x]['boro_nm'])\n",
    "        offense_desc.append(json_results[x]['ofns_desc'])\n",
    "        pd_desc.append(json_results[x]['pd_desc'])\n",
    "        law_cat.append(json_results[x]['law_cat_cd'])\n",
    "        lat.append(json_results[x]['latitude'])\n",
    "        lon.append(json_results[x]['longitude'])\n",
    "    # Update the offset number by 1000\n",
    "    offset = limit + offset\n",
    "    # Update the set count\n",
    "    set += 1\n",
    "    # Update the records_count variable with count of json_results. Once it hits zero, loop will terminate\n",
    "    records_count = len(json_results)\n",
    "    # Delay of 1 second to avoid rate limiting\n",
    "    time.sleep(1)\n",
    "# Once loop condition is no longer true, print total number of records    \n",
    "else: print(f\"Total number of records extracted: {records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = pd.DataFrame({\n",
    "    \"Complaint Number\":complaint_number,\n",
    "\"Reported Date\":reported_date,\n",
    "\"Borough\":borough_name,\n",
    "\"Offense Desc\":offense_desc,\n",
    "\"Police Desc\": pd_desc,\n",
    "\"Law Cat\":law_cat,\n",
    "\"Latitude\":lat,\n",
    "\"Longitude\":lon\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-01-01T00:00:00.000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_df['Reported Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118688 entries, 0 to 118687\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   Complaint Number  118688 non-null  object\n",
      " 1   Reported Date     118688 non-null  object\n",
      " 2   Borough           118688 non-null  object\n",
      " 3   Offense Desc      118688 non-null  object\n",
      " 4   Police Desc       118688 non-null  object\n",
      " 5   Law Cat           118688 non-null  object\n",
      " 6   Latitude          118688 non-null  object\n",
      " 7   Longitude         118688 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "crime_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
